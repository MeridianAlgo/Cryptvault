"""Linear models for cryptocurrency price prediction."""

import numpy as np
from typing import List, Tuple, Optional
import logging
from datetime import datetime, timedelta

from ...data.models import PriceDataFrame


class LinearPredictor:
    """Simple linear regression model for price prediction."""

    def __init__(self):
        """Initialize linear predictor."""
        self.logger = logging.getLogger(__name__)
        self.is_trained = False
        self.weights = None
        self.bias = 0.0
        self.feature_count = 0

    def train(self, features: np.ndarray, targets: np.ndarray) -> bool:
        """
        Train the linear model.

        Args:
            features: Feature matrix (n_samples, n_features)
            targets: Target values (n_samples,)

        Returns:
            True if training successful
        """
        try:
            if features.shape[0] != targets.shape[0]:
                raise ValueError("Features and targets must have same number of samples")

            # Add bias term
            X = np.column_stack([np.ones(features.shape[0]), features])

            # Simple linear regression using normal equation
            # Î¸ = (X^T X)^(-1) X^T y
            XtX = np.dot(X.T, X)
            XtX_inv = np.linalg.pinv(XtX)  # Use pseudo-inverse for stability
            Xty = np.dot(X.T, targets)
            theta = np.dot(XtX_inv, Xty)

            self.bias = theta[0]
            self.weights = theta[1:]
            self.feature_count = features.shape[1]
            self.is_trained = True

            self.logger.info(f"Linear model trained with {features.shape[1]} features")
            return True

        except Exception as e:
            self.logger.error(f"Linear model training failed: {e}")
            return False

    def predict(self, features: np.ndarray) -> np.ndarray:
        """
        Make predictions using the trained model.

        Args:
            features: Feature matrix (n_samples, n_features)

        Returns:
            Predictions array
        """
        try:
            if not self.is_trained:
                # Return simple trend-based predictions as fallback
                return self._fallback_predictions(features)

            if features.shape[1] != self.feature_count:
                # Try to adapt features to match expected dimension
                if features.shape[1] > self.feature_count:
                    # Take first N features
                    features = features[:, :self.feature_count]
                elif features.shape[1] < self.feature_count:
                    # Pad with zeros
                    padding = np.zeros((features.shape[0], self.feature_count - features.shape[1]))
                    features = np.hstack([features, padding])
                self.logger.warning(f"Feature dimension mismatch: expected {self.feature_count}, got {features.shape[1]}. Adjusted.")

            # Linear prediction: y = X * w + b
            predictions = np.dot(features, self.weights) + self.bias

            return predictions

        except Exception as e:
            self.logger.error(f"Linear model prediction failed: {e}")
            return self._fallback_predictions(features)

    def predict_sequence(self, features: np.ndarray, steps: int = 7) -> List[float]:
        """
        Predict a sequence of future values.

        Args:
            features: Current feature vector
            steps: Number of steps to predict

        Returns:
            List of predicted values
        """
        try:
            if not self.is_trained:
                return self._fallback_sequence_predictions(steps)

            predictions = []
            current_features = features.copy()

            for _ in range(steps):
                # Predict next value
                pred = self.predict(current_features.reshape(1, -1))[0]
                predictions.append(pred)

                # Update features for next prediction (simple approach)
                # In practice, this would involve more sophisticated feature updating
                current_features = self._update_features_for_next_step(current_features, pred)

            return predictions

        except Exception as e:
            self.logger.error(f"Sequence prediction failed: {e}")
            return self._fallback_sequence_predictions(steps)

    def _update_features_for_next_step(self, features: np.ndarray, prediction: float) -> np.ndarray:
        """Update features for the next prediction step."""
        # Simple feature update - in practice this would be more sophisticated
        updated_features = features.copy()

        # Update momentum-related features (assuming first few features are price-related)
        if len(updated_features) > 5:
            # Shift price change features
            updated_features[0] = prediction * 0.01  # Normalized price change
            updated_features[1] = updated_features[0] * 0.5  # Momentum decay

        return updated_features

    def _fallback_predictions(self, features: np.ndarray) -> np.ndarray:
        """Generate fallback predictions when model is not trained."""
        # Simple trend-based prediction
        n_samples = features.shape[0]

        # Use first feature as trend indicator if available
        if features.shape[1] > 0:
            trend = np.mean(features[:, 0]) * 0.01  # Small trend factor
        else:
            trend = 0.0

        # Generate predictions with small random variation
        predictions = np.array([trend + np.random.normal(0, 0.005) for _ in range(n_samples)])

        return predictions

    def _fallback_sequence_predictions(self, steps: int) -> List[float]:
        """Generate fallback sequence predictions."""
        # Simple random walk with slight upward bias
        predictions = []
        current_change = 0.0

        for _ in range(steps):
            # Random walk with mean reversion
            change = current_change * 0.8 + np.random.normal(0.001, 0.01)
            predictions.append(change)
            current_change = change

        return predictions

    def get_feature_importance(self) -> Optional[np.ndarray]:
        """Get feature importance (absolute weights)."""
        if self.is_trained and self.weights is not None:
            return np.abs(self.weights)
        return None

    def evaluate(self, features: np.ndarray, targets: np.ndarray) -> dict:
        """
        Evaluate model performance.

        Args:
            features: Test features
            targets: True target values

        Returns:
            Dictionary of evaluation metrics
        """
        try:
            predictions = self.predict(features)

            # Calculate metrics
            mse = np.mean((predictions - targets) ** 2)
            rmse = np.sqrt(mse)
            mae = np.mean(np.abs(predictions - targets))

            # R-squared
            ss_res = np.sum((targets - predictions) ** 2)
            ss_tot = np.sum((targets - np.mean(targets)) ** 2)
            r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

            # Directional accuracy
            pred_direction = np.sign(predictions)
            true_direction = np.sign(targets)
            directional_accuracy = np.mean(pred_direction == true_direction)

            return {
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'r2': r2,
                'directional_accuracy': directional_accuracy,
                'n_samples': len(targets)
            }

        except Exception as e:
            self.logger.error(f"Model evaluation failed: {e}")
            return {
                'mse': float('inf'),
                'rmse': float('inf'),
                'mae': float('inf'),
                'r2': 0.0,
                'directional_accuracy': 0.5,
                'n_samples': 0
            }


class ARIMAPredictor:
    """Simple ARIMA-like predictor for time series."""

    def __init__(self, p: int = 2, d: int = 1, q: int = 1):
        """
        Initialize ARIMA predictor.

        Args:
            p: Order of autoregression
            d: Degree of differencing
            q: Order of moving average
        """
        self.p = p
        self.d = d
        self.q = q
        self.logger = logging.getLogger(__name__)
        self.is_trained = False
        self.ar_params = None
        self.ma_params = None
        self.residuals = None

    def fit(self, prices: List[float]) -> bool:
        """
        Fit ARIMA model to price series.

        Args:
            prices: List of historical prices

        Returns:
            True if fitting successful
        """
        try:
            if len(prices) < max(self.p, self.q) + self.d + 10:
                self.logger.warning("Insufficient data for ARIMA fitting")
                return False

            # Difference the series
            diff_series = self._difference_series(prices, self.d)

            # Fit AR parameters using simple least squares
            self.ar_params = self._fit_ar_parameters(diff_series)

            # Calculate residuals and fit MA parameters
            ar_predictions = self._apply_ar_model(diff_series)
            self.residuals = np.array(diff_series[self.p:]) - ar_predictions
            self.ma_params = self._fit_ma_parameters(self.residuals)

            self.is_trained = True
            self.logger.info(f"ARIMA({self.p},{self.d},{self.q}) model fitted")
            return True

        except Exception as e:
            self.logger.error(f"ARIMA fitting failed: {e}")
            return False

    def forecast(self, steps: int = 7) -> List[float]:
        """
        Forecast future values.

        Args:
            steps: Number of steps to forecast

        Returns:
            List of forecasted values
        """
        if not self.is_trained:
            return [0.01] * steps  # Return small positive changes as fallback

        try:
            forecasts = []

            for _ in range(steps):
                # Simple AR forecast (simplified implementation)
                if len(self.residuals) >= self.p:
                    ar_forecast = np.dot(self.ar_params, self.residuals[-self.p:])
                else:
                    ar_forecast = 0.0

                # Add MA component (simplified)
                ma_forecast = 0.0
                if len(self.residuals) >= self.q and self.ma_params is not None:
                    ma_forecast = np.dot(self.ma_params, self.residuals[-self.q:])

                forecast = ar_forecast + ma_forecast
                forecasts.append(forecast)

                # Update residuals for next forecast
                self.residuals = np.append(self.residuals, forecast)

            return forecasts

        except Exception as e:
            self.logger.error(f"ARIMA forecasting failed: {e}")
            return [0.01] * steps

    def _difference_series(self, series: List[float], d: int) -> List[float]:
        """Apply differencing to make series stationary."""
        diff_series = series.copy()

        for _ in range(d):
            diff_series = [diff_series[i] - diff_series[i-1] for i in range(1, len(diff_series))]

        return diff_series

    def _fit_ar_parameters(self, series: List[float]) -> np.ndarray:
        """Fit AR parameters using least squares."""
        if len(series) <= self.p:
            return np.zeros(self.p)

        # Create lagged matrix
        X = []
        y = []

        for i in range(self.p, len(series)):
            X.append(series[i-self.p:i])
            y.append(series[i])

        X = np.array(X)
        y = np.array(y)

        # Solve using least squares
        try:
            params = np.linalg.lstsq(X, y, rcond=None)[0]
            return params
        except:
            return np.zeros(self.p)

    def _apply_ar_model(self, series: List[float]) -> np.ndarray:
        """Apply AR model to get predictions."""
        if self.ar_params is None or len(series) <= self.p:
            return np.zeros(max(0, len(series) - self.p))

        predictions = []

        for i in range(self.p, len(series)):
            pred = np.dot(self.ar_params, series[i-self.p:i])
            predictions.append(pred)

        return np.array(predictions)

    def _fit_ma_parameters(self, residuals: np.ndarray) -> Optional[np.ndarray]:
        """Fit MA parameters (simplified implementation)."""
        if len(residuals) <= self.q:
            return np.zeros(self.q)

        # Simplified MA fitting - in practice would use more sophisticated methods
        return np.ones(self.q) * 0.1  # Small MA coefficients
